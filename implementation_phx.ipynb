{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of ML Database Generation\n",
    "\n",
    "This notebook processes radar data and storm report data and produces a file of radar scan storm objects.\n",
    "\n",
    "This methodology follows a few important steps:\n",
    "* Loops through radar scans: each scan is treated as a distinct entity. \n",
    "* Calculates storm objects using the TINT package\n",
    "* Determines if storm is present in the Phoenix metro area (this step may be ignored for other locations)\n",
    "* Determines if the storm size is small enough to be considered cellular\n",
    "* Determines if there are reports nearby (spatially and temporally)\n",
    "\n",
    "### 1. Important packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For general data handling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#For radar data processing\n",
    "import pyart\n",
    "\n",
    "#For date/time handling\n",
    "from datetime import timedelta\n",
    "from datetime import datetime as dt\n",
    "import datetime\n",
    "from netCDF4 import num2date\n",
    "import pytz #timezone handling\n",
    "\n",
    "#For storm tracking:\n",
    "from tint import Cell_tracks, animate\n",
    "\n",
    "#For storm reports (including shapefile):\n",
    "import geopandas as gpd\n",
    "\n",
    "#For coordinate systems:\n",
    "from pyproj import Proj\n",
    "\n",
    "#For mapping (helping with storm reports):\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "from metpy.plots import USCOUNTIES\n",
    "\n",
    "#For handling files\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Important Helper-Functions\n",
    "\n",
    "These functions are used to standardize the conversion of radar files to grids in PyART.\n",
    "\n",
    "#### 2.1 Function Parameters\n",
    "\n",
    "These parameters are passed the the functions below. The comments indicate what aspects of the gridding process they control."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_spacing_v = 35 #normal = 30 - corresponds 586 m (35 corresponds to 500 m)\n",
    "grid_spacing_h = 201 #normal = 200 - corresponds to roughly 1 km (201 corresponds to 1 km)\n",
    "grid_interpolation_scheme = \"map_gates_to_grid\" #map_gates_to_grid best\n",
    "weighting_function = \"Barnes2\" #radius of influence scheme\n",
    "roi_func = \"dist\" #constant or dist or dist_beam\n",
    "constant_roi = 500. #for constant radius of influence (not used)\n",
    "top_level = 17000 #height of top level in meters\n",
    "\n",
    "#FOR DISTANCE RADIUS OF INFLUENCE\n",
    "z_factor = 0.05\n",
    "xy_factor = 0.01\n",
    "min_radius = 500."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2. get_grid function\n",
    "\n",
    "This function calls the PyART grid_from_radars function with the parameters described above. It then returns a grid object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_grid(radar, vert_grid_spacing = grid_spacing_v, hor_grid_spacing = grid_spacing_h, algo = grid_interpolation_scheme,\n",
    "            weighting_function = weighting_function, roi_func = roi_func, constant_roi = constant_roi,\n",
    "            z_factor = z_factor, xy_factor = xy_factor, min_radius = min_radius, top_level = top_level):\n",
    "    # Returns grid object from radar object.\n",
    "    grid = pyart.map.grid_from_radars((radar,), grid_shape = (vert_grid_spacing, hor_grid_spacing, hor_grid_spacing),\n",
    "                                      grid_limits = ((0,top_level),(-100000.0, 100000.0), (-100000.0, 100000.0)),\n",
    "                                      fields = ['reflectivity'],\n",
    "                                      gridding_algo = algo, \n",
    "                                      weighting_function = weighting_function,\n",
    "                                      roi_func = roi_func,\n",
    "                                      constant_roi = constant_roi,\n",
    "                                      z_factor = z_factor, xy_factor = xy_factor, min_radius = min_radius)\n",
    "    return grid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3. calculate_vil function\n",
    "\n",
    "This function implements a formula to calculate vertically integrated liquid (VIL) on a grid, and returns the resulting calculated values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_vil(radar_grid, vert_grid_spacing = grid_spacing_v, top_level = top_level):\n",
    "    exp = radar_grid/10\n",
    "    z_new = np.power(10, exp)\n",
    "    delta_h = top_level/(vert_grid_spacing-1)\n",
    "    VIL = (3.44*10**(-6))*delta_h*np.sum(np.power(z_new, (4/7)), axis = 0)\n",
    "    return VIL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.4. calculate_echo_tops function\n",
    "\n",
    "This function implements a formula to calculate maximum echo tops on a radar grid for a given threshold, and returns the resulting calculated values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_echo_tops(radar_grid, threshold, vert_grid_spacing = grid_spacing_v, top_level = top_level):\n",
    "    delta_h = top_level/(vert_grid_spacing-1)\n",
    "    heights = np.arange(0,17001, delta_h)\n",
    "    heights_arr = np.zeros(np.shape(radar_grid))\n",
    "    i = 0\n",
    "    while i < len(heights):\n",
    "        heights_arr[i, :, :] = heights[i]\n",
    "        i = i+1\n",
    "    mask = np.logical_or(radar_grid < threshold, radar_grid.mask)\n",
    "    heights_masked = np.ma.masked_array(heights_arr, mask = mask)\n",
    "    ets = (heights_masked.max(axis = 0))\n",
    "    return ets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Data preprocessing:\n",
    "\n",
    "Before radar data and storm reports can be paired into a database of severe and sub-severe storm objects, the different data sources must be prepared. \n",
    "\n",
    "#### 3.1. Creating a UTM projection for converting lat/lon data to distances:\n",
    "\n",
    "This projection will be used later in the calculation of distances between lat/lon points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myProj = Proj(\"+proj=utm +zone=12, +ellps=WGS84 +datum=WGS84 +units=m +no_defs\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2. Loading the Phoenix Metro Area shapefile:\n",
    "\n",
    "This shapefile is a boundary for the Phoenix metro area. This boundary was developed by hand by the NWS Phoenix office. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phx_shapefile_path = \"./Phoenix Metro.shx\"\n",
    "phx_shapefile = gpd.read_file(phx_shapefile_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3. Loading and processing the storm reports:\n",
    "\n",
    "The file (stored in wind_path) contains storm report data within only the region of interest (ex. Maricopa County, AZ). Only certain variables are important to this project (Begin date, time, and location). Additional processing was required:\n",
    "* The coordinate system was changed to UTM to aid in the use of distances\n",
    "* Invalid times were removed\n",
    "* Report times and dates were combined and converted into UTC time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wind_path = \"./storm_data_tswind50.csv\"\n",
    "wind = pd.read_csv(wind_path)[['BEGIN_DATE', 'BEGIN_TIME', 'CZ_TIMEZONE', 'BEGIN_LAT', 'BEGIN_LON', 'MAGNITUDE']]\n",
    "\n",
    "#changing coordinate system to UTM\n",
    "wind['UTMx'], wind['UTMy'] = myProj(wind['BEGIN_LON'].values, wind['BEGIN_LAT'].values)\n",
    "wind = gpd.GeoDataFrame(wind, geometry = gpd.points_from_xy(wind.UTMx,wind.UTMy))\n",
    "\n",
    "#removing invalid data points\n",
    "wind_isel =wind['BEGIN_TIME'] > 0\n",
    "wind = wind[wind_isel]\n",
    "\n",
    "#processing the date and time\n",
    "report_time = wind['BEGIN_TIME'][wind_isel] #these are ints\n",
    "report_date = wind['BEGIN_DATE'][wind_isel] #these are strings\n",
    "\n",
    "time_true = []\n",
    "for d, t in zip(report_date, report_time):\n",
    "    time_str = d + \" \" + str(t)\n",
    "    dt_temp = dt.strptime(time_str, \"%m/%d/%Y %H%M\")\n",
    "    dt_final = pytz.timezone('US/Arizona').localize(dt_temp)\n",
    "    dt_final = dt_final.astimezone(pytz.timezone('UTC'))\n",
    "    time_true.append(dt_final)\n",
    "\n",
    "wind['true_time'] = time_true"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4. Locating radar files:\n",
    "\n",
    "This small loop generates a list of radar scans to utilize. The radar scans are located in the directory given by PATH. The PATH variable should be changed to where radar data is located. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radar_scans = []\n",
    "\n",
    "PATH = \"./radar_data_KIWA/2018-9\"\n",
    "for filename in os.listdir(PATH):\n",
    "    if filename.endswith(\"_MDM\"):continue\n",
    "    else: radar_scans.append(PATH + \"/\" + filename)\n",
    "        \n",
    "radar_scans.sort()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5. Defining final dataframe structure:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "storm_dataset = pd.DataFrame(columns = ['Datetime','lat','lon', 'area', 'vol', 'max_vil',\n",
    "                                        'max_refl','max_alt','max_et18', 'max_et50', 'max_et60', 'severe_5km',\n",
    "                                        'severe_10km', 'severe_15km'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Database Generation: \n",
    "\n",
    "This section generates the database of storm objects paired with storm reports.\n",
    "\n",
    "#### 4.1. Defining important parameters:\n",
    "\n",
    "There are several parameters that must be defined. \n",
    "* area_threshold: The largest area, in square kilometers, of thunderstorms added to the database. This value is set to 100, removing any large thunderstorm complexes from consideration.\n",
    "* refl_threshold: The reflectivity requried for a storm object to be considered\n",
    "* report_threshold_forward: The time (in minutes) after a radar scan to pair a report with the storm. Set to 20 minutes\n",
    "* report_threshold_backward: The time (in minutes) before a radar scan to pair a report with the storm and classify the storm as 'recently severe'\n",
    "* radar_buffer: The radius (in kilometers) around the radar to ignore. This is done to remove the influence of the lack of data directly above the radar. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_threshold = 100. #Largest area thunderstorm included (km2)\n",
    "refl_threshold = 45. #Refl required for storm object\n",
    "report_threshold_forward = 20. #how many minutes forward to search for reports\n",
    "report_threshold_backward = -15. #how many minutes backward to search for reports (for third subset)\n",
    "radar_buffer = 30000. #buffer aroud radar location to ignore storms (in meters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2. Database generation loop\n",
    "\n",
    "This code block loops through all of the radar scans. For each radar scan (if there are no errors in loading the scan), a radar grid is generated and storm objects are identified. For each storm object:\n",
    "1. The location is checked to confirm the storm is in the Phoenix metro area\n",
    "2. The location is checked to confirm the storm is outside of the radar buffer region\n",
    "3. The size of the storm is checked to ensure it is of small enough size\n",
    "4. The radar is paired to storm reports within a 5-km, 10-km, and 15-km radius from the storm centroid\n",
    "5. Storm attributes are calculated and stored in the final dataframe\n",
    "\n",
    "At the end of the loop, the output is saved to a file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "errors = 0\n",
    "i = 0\n",
    "\n",
    "for radar_scan in radar_scans:\n",
    "    \n",
    "    try:\n",
    "        grid = get_grid(pyart.io.read_nexrad_archive(radar_scan)) #Try to streamline this\n",
    "        grids = (g for g in [grid])\n",
    "\n",
    "        # Calculate storm tracks/ids (using TINT)\n",
    "        tracks_obj = Cell_tracks()\n",
    "        tracks_obj.params['FIELD_THRESH'] = refl_threshold\n",
    "        tracks_obj.get_tracks(grids)\n",
    "\n",
    "        df = tracks_obj.tracks.copy()\n",
    "        df = df.reset_index() #df will contain all of our storm information\n",
    "\n",
    "        if len(df) > 0:\n",
    "\n",
    "            for uid in df.uid:\n",
    "                uid_isel = df.uid == uid\n",
    "\n",
    "                centroid = gpd.points_from_xy([df['lon'][uid_isel]], [df['lat'][uid_isel]])[0]\n",
    "\n",
    "                centroid_utm_x, centroid_utm_y = myProj([df['lon'][uid_isel].values], [df['lat'][uid_isel].values])\n",
    "                centroid_utm = gpd.points_from_xy(centroid_utm_x, centroid_utm_y)[0]\n",
    "\n",
    "                inside_phx = centroid.within(phx_shapefile.geometry[0])\n",
    "\n",
    "                radar_lat = grid.origin_latitude['data'][0]\n",
    "                radar_lon = grid.origin_longitude['data'][0]\n",
    "\n",
    "                radar_utm_x, radar_utm_y = myProj([radar_lon], [radar_lat])\n",
    "\n",
    "                radar_centroid = gpd.points_from_xy(radar_utm_x,radar_utm_y)[0]\n",
    "                radar_buf = radar_centroid.buffer(30000.)\n",
    "\n",
    "                inside_radar_range = centroid_utm.within(radar_buf)\n",
    "\n",
    "                if inside_phx == True and inside_radar_range == False:\n",
    "\n",
    "                    if df.area[uid_isel].values[0] < area_threshold:\n",
    "                        \n",
    "                        severe_5km = 0\n",
    "                        severe_10km = 0\n",
    "                        severe_15km = 0\n",
    "\n",
    "                        dts = num2date(grid.time['data'], grid.time['units'])\n",
    "                        dts = pytz.timezone('UTC').localize(dts[0])\n",
    "                        datestr = dts.strftime('%H:%M UTC %Y-%m-%d')\n",
    "\n",
    "                        delta_mins = []\n",
    "\n",
    "                        for d in time_true:\n",
    "                            delta = d - dts\n",
    "                            delta_min = delta.days*24*60 + delta.seconds/60\n",
    "                            delta_mins.append(delta_min)\n",
    "\n",
    "                        delta_mins = np.array(delta_mins)\n",
    "                        time_isel = np.logical_and(delta_mins >= 0.0, delta_mins <= report_threshold_forward)\n",
    "                        time_isel_past = np.logical_and(delta_mins < 0.0, delta_mins >= report_threshold_backward)\n",
    "\n",
    "\n",
    "                        ###### 5 km radius #######################\n",
    "                        report_buffer = 5000.\n",
    "\n",
    "                        if np.sum(time_isel) > 0:\n",
    "                            report_subset = wind[time_isel]\n",
    "                            nearby_reports_isel = report_subset.within(centroid_utm.buffer(report_buffer))\n",
    "                            if np.sum(nearby_reports_isel) > 0:\n",
    "                                severe_5km = 1\n",
    "\n",
    "                        if np.sum(time_isel_past) > 0:\n",
    "                            report_subset_past = wind[time_isel_past]\n",
    "                            nearby_reports_past_isel = report_subset_past.within(centroid_utm.buffer(report_buffer))\n",
    "                            if np.sum(nearby_reports_past_isel) > 0:\n",
    "                                if severe_5km == 0:\n",
    "                                    severe_5km = -1\n",
    "\n",
    "                        ###### 10 km radius #######################\n",
    "                        report_buffer = 10000.\n",
    "\n",
    "                        if np.sum(time_isel) > 0:\n",
    "                            report_subset = wind[time_isel]\n",
    "                            nearby_reports_isel = report_subset.within(centroid_utm.buffer(report_buffer))\n",
    "                            if np.sum(nearby_reports_isel) > 0:\n",
    "                                severe_10km = 1\n",
    "\n",
    "                        if np.sum(time_isel_past) > 0:\n",
    "                            report_subset_past = wind[time_isel_past]\n",
    "                            nearby_reports_past_isel = report_subset_past.within(centroid_utm.buffer(report_buffer))\n",
    "                            if np.sum(nearby_reports_past_isel) > 0:\n",
    "                                if severe_10km == 0:\n",
    "                                    severe_10km = -1\n",
    "\n",
    "                        ###### 15 km radius ########################\n",
    "                        report_buffer = 15000.\n",
    "\n",
    "                        if np.sum(time_isel) > 0:\n",
    "                            report_subset = wind[time_isel]\n",
    "                            nearby_reports_isel = report_subset.within(centroid_utm.buffer(report_buffer))\n",
    "                            if np.sum(nearby_reports_isel) > 0:\n",
    "                                severe_15km = 1\n",
    "\n",
    "                        if np.sum(time_isel_past) > 0:\n",
    "                            report_subset_past = wind[time_isel_past]\n",
    "                            nearby_reports_past_isel = report_subset_past.within(centroid_utm.buffer(report_buffer))\n",
    "                            if np.sum(nearby_reports_past_isel) > 0:\n",
    "                                if severe_15km == 0:\n",
    "                                    severe_15km = -1\n",
    "\n",
    "                        ##### CALCULATING ATTRIBUTES ##################################################################\n",
    "                        x_centered = int(df.grid_x[uid_isel].values.round())\n",
    "                        y_centered = int(df.grid_y[uid_isel].values.round())\n",
    "                        lon_centered = df.lon[uid_isel].values\n",
    "                        lat_centered = df.lat[uid_isel].values\n",
    "\n",
    "                        x = 2\n",
    "\n",
    "                        radar_subset = grid.fields['reflectivity']['data'][:][:,y_centered-x:y_centered+x, x_centered-x:x_centered+x]\n",
    "\n",
    "                        # Here are attributes - need to determine what attributes to calculate\n",
    "                        max_vil = np.max(calculate_vil(radar_subset))\n",
    "                        max_et18 = np.max(calculate_echo_tops(radar_subset, threshold = 18.5))\n",
    "                        max_et50 = np.max(calculate_echo_tops(radar_subset, threshold = 50.))\n",
    "                        max_et60 = np.max(calculate_echo_tops(radar_subset, threshold = 60.))\n",
    "\n",
    "                        storm_dataset = storm_dataset.append({'Datetime': datestr,'lat':df['lat'][uid_isel].values[0],\n",
    "                                            'lon':df['lon'][uid_isel].values[0], 'max_vil' : max_vil,'max_et18':max_et18,\n",
    "                                            'max_refl': df['max'][uid_isel].values[0],'max_alt':df['max_alt'][uid_isel].values[0],\n",
    "                                            'area':df['area'][uid_isel].values[0], 'vol':df['vol'][uid_isel].values[0],\n",
    "                                            'max_et50': max_et50, 'max_et60':max_et60, 'severe_5km':severe_5km,\n",
    "                                            'severe_10km':severe_10km, 'severe_15km':severe_15km}, ignore_index = True)\n",
    "\n",
    "        print(\"Done with scan #\" + str(i)+\": \" + radar_scan)\n",
    "\n",
    "        i = i+1\n",
    "    \n",
    "    except:\n",
    "        print(\"error in handling radar scan #\" + str(i) + \": \" + radar_scan)\n",
    "        errors = errors + 1\n",
    "        i = i+1\n",
    "                \n",
    "# output to file\n",
    "#storm_dataset.to_csv(\"storm_dataset_phx201809_full_noradar_varbuffers.csv\",sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional Helpful Information:\n",
    "\n",
    "#### df columns: \n",
    "* scan: always 0\n",
    "* uid: object id, this is what we iterate over\n",
    "* time: date and time object (timestamp object):\n",
    "* grid_x, grid_y: grid locations of centroid\n",
    "* lon, lat: lat/lon locations of centroid\n",
    "* area: area of cell\n",
    "* vol: volume of cell\n",
    "* max: maximum reflectivity\n",
    "* max_alt: altitude of maximum reflectivity\n",
    "* isolated: is the cell isolated\n",
    "\n",
    "#### Variables in storm dataset:\n",
    "* date/time: storm time\n",
    "* lat/lon: storm location\n",
    "* max_vil: maximum VIL\n",
    "* max_et18: 18.5 dBZ echo top height\n",
    "* max_et50: 50 dBZ echo top height\n",
    "* max_et60: 60 dBZ echo top height\n",
    "* max_refl: maximum reflectivity (from tint)\n",
    "* max_alt: height of maximum reflectivity (from tint)\n",
    "* area: storm area (from tint)\n",
    "* volume: storm volume (from tint)\n",
    "\n",
    "#### Lagerquist et al. 2017 variables:\n",
    "* Used reflectivity at three temperature levels (-20C, -10C, 0C)\n",
    "* Nine composite radar variables: composite reflectivity, low-level reflectivity, severe hail index (SHI), vertically integrated liquid (VIL), maximum estimated hail size (MESH), midlevel (3-6 km) shear, low-level (0-2 km) shear\n",
    "* Model sounding data (RUC/NARR):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#storm_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
